{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpy0UdcYsS5eYqIK2iaSxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/budialis/Data-Mining/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TawG9BZDf6nW",
        "outputId": "02e5c429-731b-4dd7-df1b-4655333a8685"
      },
      "source": [
        "# python syntax for simulating k-means in google colab\n",
        "# connect to google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0grOu7gC5K",
        "outputId": "20a0e244-1d09-4846-c8d7-6f895ee902b4"
      },
      "source": [
        "# install turicreate framework\n",
        "!pip install -U turicreate"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting turicreate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/9f/a76acc465d873d217f05eac4846bd73d640b9db6d6f4a3c29ad92650fbbe/turicreate-6.4.1-cp37-cp37m-manylinux1_x86_64.whl (92.0MB)\n",
            "\u001b[K     |████████████████████████████████| 92.0MB 44kB/s \n",
            "\u001b[?25hCollecting numba<0.51.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/be/8c88cee3366de2a3a23a9ff1a8be34e79ad1eb1ceb0d0e33aca83655ac3c/numba-0.50.1-cp37-cp37m-manylinux2014_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 39.8MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/b3/3eeae9bc44039ceadceac0c7ba1cc8b1482b172810b3d7624a1cad251437/tensorflow-2.0.4-cp37-cp37m-manylinux2010_x86_64.whl (86.4MB)\n",
            "\u001b[K     |████████████████████████████████| 86.4MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.15.0)\n",
            "Collecting coremltools==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/1d/b1a99beca7355b6a026ae61fd8d3d36136e5b36f13e92ec5f81aceffc7f1/coremltools-3.3-cp37-none-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 27.6MB/s \n",
            "\u001b[?25hCollecting resampy==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b6/66a06d85474190b50aee1a6c09cdc95bb405ac47338b27e9b21409da1760/resampy-0.2.1.tar.gz (322kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.19.5)\n",
            "Collecting prettytable==0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.0.9 in /usr/local/lib/python3.7/dist-packages (from turicreate) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from turicreate) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<0.51.0->turicreate) (56.0.0)\n",
            "Collecting llvmlite<0.34,>=0.33.0.dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/28/0a35b3c2685bf2ea327cef5577bdf91f387f0f4594417a2a05a1d42fb7c2/llvmlite-0.33.0-cp37-cp37m-manylinux1_x86_64.whl (18.3MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3MB 253kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.5MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.1.0)\n",
            "Building wheels for collected packages: resampy, prettytable, gast\n",
            "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resampy: filename=resampy-0.2.1-cp37-none-any.whl size=320845 sha256=9129f481726836026f693b8fe17789dbc40e3063efa4a48db33147d3d1f8072e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/4f/ed/2e6c676c23efe5394bb40ade50662e90eb46e29b48324c5f9b\n",
            "  Building wheel for prettytable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prettytable: filename=prettytable-0.7.2-cp37-none-any.whl size=13700 sha256=80cc5afc8c25d1a9d4acff9515f7195cf5d685ca57ac5e86f9c5094439edfaf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=a7915c43bcab7c31701d4f30a3e90c570c5055c3e2cf7f4b6a5efdb8344899b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built resampy prettytable gast\n",
            "\u001b[31mERROR: tensorflow 2.0.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement resampy>=0.2.2, but you'll have resampy 0.2.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: llvmlite, numba, tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow, coremltools, resampy, prettytable, turicreate\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: resampy 0.2.2\n",
            "    Uninstalling resampy-0.2.2:\n",
            "      Successfully uninstalled resampy-0.2.2\n",
            "  Found existing installation: prettytable 2.1.0\n",
            "    Uninstalling prettytable-2.1.0:\n",
            "      Successfully uninstalled prettytable-2.1.0\n",
            "Successfully installed coremltools-3.3 gast-0.2.2 keras-applications-1.0.8 llvmlite-0.33.0 numba-0.50.1 prettytable-0.7.2 resampy-0.2.1 tensorboard-2.0.2 tensorflow-2.0.4 tensorflow-estimator-2.0.1 turicreate-6.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2vGlLBygFqi"
      },
      "source": [
        "# import turicreate framework\n",
        "import turicreate"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "vacENRX1gJeb",
        "outputId": "dc6fc4a4-62f5-4713-b396-cae0b01a1b76"
      },
      "source": [
        "# import dataset\n",
        "people = turicreate.SFrame('/content/drive/MyDrive/Colab Notebooks/people_wiki.sframe')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/turicreate/data_structures/sframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, format, _proxy)\u001b[0m\n\u001b[1;32m    833\u001b[0m                     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_internal_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_sframe_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0m_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"empty\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcy_sframe.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_sframe.UnitySFrameProxy.load_from_sframe_index\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcy_sframe.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_sframe.UnitySFrameProxy.load_from_sframe_index\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/drive/MyDrive/Colab Notebooks/people_wiki.sframe not found. ErrMsg: file not exist in /content/drive/MyDrive/Colab Notebooks/people_wiki.sframe",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-af824515ec03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mturicreate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/people_wiki.sframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/turicreate/data_structures/sframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, format, _proxy)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown input type: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/turicreate/_cython/context.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_cython_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# To hide cython trace, we re-raise from here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# To show the full trace, we do nothing and let exception propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/drive/MyDrive/Colab Notebooks/people_wiki.sframe not found. ErrMsg: file not exist in /content/drive/MyDrive/Colab Notebooks/people_wiki.sframe"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puv8nf9JgLAi"
      },
      "source": [
        "# explore dataset\n",
        "people\n",
        "people[0]\n",
        "people['text'][0]\n",
        "people['URI'][2]\n",
        "people.head(10)\n",
        "people.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKodek6sgNTZ"
      },
      "source": [
        "# select a person in the dataset\n",
        "obama = people[people['name'] == 'Barack Obama']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slGq-6RygPXC"
      },
      "source": [
        "# Word counts for Obama article\n",
        "obama['word_count'] = turicreate.text_analytics.count_words(obama['text'])\n",
        "obama\n",
        "print (obama['word_count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGI0t0ekgSvi"
      },
      "source": [
        "# Find most common words in Obama\n",
        "obama.stack('word_count',new_column_name=['word','count'])\n",
        "obama_word_count_table = obama[['word_count']].stack('word_count', new_column_name = ['word','count'])\n",
        "obama_word_count_table\n",
        "obama_word_count_table.sort('count',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge67qwSDgTBJ"
      },
      "source": [
        "# Compute TF-IDF for the entire corpus of the articles\n",
        "people['word_count'] = turicreate.text_analytics.count_words(people['text'])\n",
        "people\n",
        "people['tfidf'] = turicreate.text_analytics.tf_idf(people['text'])\n",
        "people"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7C_0z3pgW4S"
      },
      "source": [
        "# Check TF-IDF result for the Obama article\n",
        "obama = people[people['name'] == 'Barack Obama']\n",
        "obama[['tfidf']].stack('tfidf',new_column_name=['word','tfidf']).sort('tfidf',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ntJOznVgY9K"
      },
      "source": [
        "# Check TF-IDF result for the Clooney article\n",
        "clooney = people[people['name'] == 'George Clooney']\n",
        "clooney[['tfidf']].stack('tfidf',new_column_name=['word','tfidf']).sort('tfidf',ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od-RjGgigbSp"
      },
      "source": [
        "# Create NN-model\n",
        "knn_model = turicreate.nearest_neighbors.create(people,features=['tfidf'],label='name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WvBIgXOgc6x"
      },
      "source": [
        "# Let's use the model\n",
        "knn_model.query(obama)\n",
        "swift = people[people['name'] == 'Taylor Swift']\n",
        "knn_model.query(swift)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}